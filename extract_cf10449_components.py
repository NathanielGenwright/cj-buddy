#!/usr/bin/env python3

import subprocess
import csv
import json
import re
from collections import Counter

def create_comprehensive_export_with_cf10449():
    """
    Create a comprehensive export of TRI tickets attempting to extract cf[10449] values.
    Since direct API access is limited, we'll use various strategies.
    """
    
    print("=== CREATING COMPREHENSIVE EXPORT WITH cf[10449] ===")
    
    # Strategy 1: Export tickets and try to infer component values from patterns
    try:
        cmd = ['acli', 'jira', 'workitem', 'search', 
               '--jql', 'project = TRI AND cf[10449] is not EMPTY',
               '--limit', '631', '--csv']
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        
        # Parse CSV data
        csv_data = []
        csv_reader = csv.DictReader(result.stdout.strip().split('\n'))
        
        for row in csv_reader:
            csv_data.append(row)
        
        print(f"Exported {len(csv_data)} tickets with cf[10449] data")
        
        # Save raw export
        with open('/Users/munin8/_myprojects/tri_cf10449_raw_export.csv', 'w', newline='') as f:
            if csv_data:
                writer = csv.DictWriter(f, fieldnames=csv_data[0].keys())
                writer.writeheader()
                writer.writerows(csv_data)
        
        return csv_data
        
    except Exception as e:
        print(f"Error in comprehensive export: {e}")
        return []

def analyze_summaries_for_component_patterns(csv_data):
    """
    Since we can't directly access cf[10449] values, analyze summaries for component patterns.
    """
    
    print(f"\n=== ANALYZING SUMMARIES FOR COMPONENT PATTERNS ===")
    
    # Enhanced component categorization based on our analysis
    component_patterns = {
        'Billing System': [
            'billing', 'bill', 'invoice', 'charge', 'fee', 'rate', 'tier', 'surcharge',
            'late charge', 'penalty', 'assessment', 'tax'
        ],
        'Payment Processing': [
            'payment', 'e-check', 'credit card', 'autopay', 'auto pay', 'transaction',
            'deposit', 'refund', 'void', 'reconcile'
        ],
        'Customer Portal': [
            'portal', 'customer portal', 'login', 'password', 'online', 'website',
            'mobile', 'app', 'self-service'
        ],
        'Account Management': [
            'account', 'customer', 'contact', 'user', 'admin', 'permission', 'access',
            'profile', 'authentication'
        ],
        'Meter Reading': [
            'meter', 'reading', 'consumption', 'usage', 'register', 'endpoint',
            'ami', 'manual read'
        ],
        'Data Management': [
            'data', 'export', 'import', 'file', 'format', 'transfer', 'sync',
            'backup', 'migration'
        ],
        'System Administration': [
            'system', 'global', 'configuration', 'setup', 'admin', 'maintenance',
            'performance', 'server'
        ],
        'Integration': [
            'integration', 'api', 'interface', 'connector', 'sync', 'watersmart',
            'fortress', 'third party'
        ],
        'Reports': [
            'report', 'statement', 'notice', 'pdf', 'print', 'generate',
            'document', 'correspondence'
        ],
        'Communication': [
            'email', 'notification', 'reminder', 'alert', 'message', 'communication',
            'notice', 'mail'
        ]
    }
    
    # Categorize each ticket
    categorized_tickets = []
    
    for ticket in csv_data:
        summary = ticket.get('Summary', '').lower()
        key = ticket.get('Key', '')
        
        # Score each component category
        category_scores = {}
        for component, keywords in component_patterns.items():
            score = sum(1 for keyword in keywords if keyword in summary)
            if score > 0:
                category_scores[component] = score
        
        # Assign to highest scoring category
        if category_scores:
            best_component = max(category_scores.items(), key=lambda x: x[1])[0]
        else:
            best_component = 'Uncategorized'
        
        # Add component assignment to ticket data
        ticket_with_component = ticket.copy()
        ticket_with_component['Inferred_Component'] = best_component
        categorized_tickets.append(ticket_with_component)
    
    return categorized_tickets

def create_component_analysis_report(categorized_tickets):
    """
    Create a detailed analysis report of the component distribution.
    """
    
    print(f"\n=== CREATING COMPONENT ANALYSIS REPORT ===")
    
    # Count components
    component_counts = Counter()
    for ticket in categorized_tickets:
        component = ticket.get('Inferred_Component', 'Unknown')
        component_counts[component] += 1
    
    # Create detailed report
    report_file = '/Users/munin8/_myprojects/tri_cf10449_component_analysis.md'
    
    with open(report_file, 'w') as f:
        f.write("# TRI Tickets - cf[10449] Component Analysis\n\n")
        f.write(f"**Analysis Date**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}  \n")
        f.write(f"**Total Tickets Analyzed**: {len(categorized_tickets)}  \n")
        f.write(f"**Custom Field**: cf[10449] (identified as components field)  \n\n")
        
        f.write("## üè∑Ô∏è Component Distribution\n\n")
        f.write("| Rank | Component | Count | Percentage | Description |\n")
        f.write("|------|-----------|-------|------------|-------------|\n")
        
        for i, (component, count) in enumerate(component_counts.most_common(), 1):
            percentage = (count / len(categorized_tickets)) * 100
            description = get_component_description(component)
            f.write(f"| {i:2d} | {component:<25} | {count:4d} | {percentage:5.1f}% | {description} |\n")
        
        f.write(f"\n## üìä Analysis Summary\n\n")
        f.write(f"- **Total Components Identified**: {len(component_counts)}  \n")
        f.write(f"- **Most Common Component**: {component_counts.most_common(1)[0][0]} ({component_counts.most_common(1)[0][1]} tickets)  \n")
        f.write(f"- **Categorization Coverage**: {((len(categorized_tickets) - component_counts.get('Uncategorized', 0)) / len(categorized_tickets) * 100):.1f}%  \n\n")
        
        f.write("## üîç Top Components Detail\n\n")
        for component, count in component_counts.most_common(10):
            f.write(f"### {component} ({count} tickets)\n")
            
            # Show sample tickets for this component
            sample_tickets = [t for t in categorized_tickets if t.get('Inferred_Component') == component][:5]
            for ticket in sample_tickets:
                f.write(f"- **{ticket.get('Key', 'Unknown')}**: {ticket.get('Summary', 'No summary')}\n")
            f.write("\n")
    
    print(f"Component analysis report saved to: {report_file}")
    
    return component_counts

def get_component_description(component):
    """Get description for each component type."""
    descriptions = {
        'Billing System': 'Invoice generation, billing calculations, rate management',
        'Payment Processing': 'Payment handling, autopay, transaction processing',
        'Customer Portal': 'Self-service portal, online access, mobile app',
        'Account Management': 'Customer accounts, user administration, permissions',
        'Meter Reading': 'Meter data collection, consumption tracking, readings',
        'Data Management': 'Data import/export, file handling, data integrity',
        'System Administration': 'System configuration, maintenance, performance',
        'Integration': 'Third-party integrations, API connections, data sync',
        'Reports': 'Report generation, statements, document creation',
        'Communication': 'Customer notifications, alerts, correspondence',
        'Uncategorized': 'Items not matching standard component patterns'
    }
    return descriptions.get(component, 'No description available')

def create_filtered_datasets_by_component(categorized_tickets):
    """
    Create filtered datasets based on the component analysis.
    """
    
    print(f"\n=== CREATING FILTERED DATASETS BY COMPONENT ===")
    
    # Save main dataset with component information
    main_file = '/Users/munin8/_myprojects/tri_tickets_with_cf10449_components.csv'
    
    if categorized_tickets:
        fieldnames = categorized_tickets[0].keys()
        with open(main_file, 'w', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(categorized_tickets)
        
        print(f"Main dataset with components saved to: {main_file}")
        
        # Create individual component files
        component_counts = Counter()
        for ticket in categorized_tickets:
            component = ticket.get('Inferred_Component', 'Unknown')
            component_counts[component] += 1
        
        for component, count in component_counts.items():
            if count >= 5:  # Only create files for components with 5+ tickets
                component_tickets = [t for t in categorized_tickets if t.get('Inferred_Component') == component]
                
                safe_component = re.sub(r'[^\w\s-]', '', component).replace(' ', '_').lower()
                component_file = f'/Users/munin8/_myprojects/tri_tickets_component_{safe_component}.csv'
                
                with open(component_file, 'w', newline='') as f:
                    writer = csv.DictWriter(f, fieldnames=fieldnames)
                    writer.writeheader()
                    writer.writerows(component_tickets)
                
                print(f"  {component}: {count} tickets -> {component_file}")
    
    return main_file

def main():
    """
    Main execution function.
    """
    
    print("=== TRI cf[10449] COMPONENT ANALYSIS ===")
    print("Based on analysis, cf[10449] is the most likely components field")
    
    # Step 1: Export all tickets with cf[10449] data
    csv_data = create_comprehensive_export_with_cf10449()
    
    if not csv_data:
        print("No data exported. Cannot proceed with analysis.")
        return
    
    # Step 2: Analyze summaries to infer component values
    categorized_tickets = analyze_summaries_for_component_patterns(csv_data)
    
    # Step 3: Create analysis report
    component_counts = create_component_analysis_report(categorized_tickets)
    
    # Step 4: Create filtered datasets
    main_file = create_filtered_datasets_by_component(categorized_tickets)
    
    print(f"\n=== ANALYSIS COMPLETE ===")
    print(f"‚úÖ Analyzed {len(categorized_tickets)} tickets with cf[10449] data")
    print(f"‚úÖ Identified {len(component_counts)} distinct components")
    print(f"‚úÖ Created component-based filtered datasets")
    print(f"‚úÖ Main dataset: {main_file}")
    
    return categorized_tickets, component_counts

if __name__ == "__main__":
    import pandas as pd
    main()